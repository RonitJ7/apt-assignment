{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e696986",
   "metadata": {},
   "source": [
    "# ðŸ“Š Analysis: Column Mapping Justification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39822bf",
   "metadata": {},
   "source": [
    "This notebook explores the statistical and structural relationships between the columns to justify the inferred mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11bf76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"data.csv\")\n",
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e46d01",
   "metadata": {},
   "source": [
    "### ðŸ” Step 1: Identifying Volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09967e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_counts = {}\n",
    "columns = df.columns\n",
    "for col in columns:\n",
    "    volume_counts[col]=0\n",
    "\n",
    "for index,row in df.iterrows():\n",
    "    candidates = []\n",
    "    for col in columns:\n",
    "        value = row[col]\n",
    "        if value > 0 and value == int(value):\n",
    "            candidates.append(col)\n",
    "    if candidates:\n",
    "        max_value = 0\n",
    "        best_col = None\n",
    "        for col in candidates:\n",
    "            if row[col] > max_value:\n",
    "                max_value = row[col]\n",
    "                best_col = col\n",
    "        volume_counts[best_col] += 1\n",
    "                    \n",
    "for col,count in volume_counts.items():\n",
    "    volume_counts[col] = count / len(df)\n",
    "max_column_volume = max(volume_counts, key=volume_counts.get)\n",
    "max_confidence = volume_counts[max_column_volume]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(volume_counts.keys(), volume_counts.values())\n",
    "plt.title('Probability of Each Column Being Volume')\n",
    "plt.xlabel('Columns')\n",
    "plt.ylabel('Probability')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Thus, Column {max_column_volume} is the most likely candidate for volume with confidence {max_confidence}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3262f10",
   "metadata": {},
   "source": [
    "### ðŸ” Step 2: Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb04dc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "print(\"\\n1. Pearson Correlation Matrix:\")\n",
    "pearson_corr = df.corr(method='pearson')\n",
    "print(pearson_corr.round(5))\n",
    "\n",
    "print(\"\\n2. Spearman Correlation Matrix:\")\n",
    "spearman_corr = df.corr(method='spearman')\n",
    "print(spearman_corr.round(5))\n",
    "\n",
    "plt.figure(figsize=(15, 13))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.heatmap(pearson_corr, annot=True, cmap='coolwarm', center=0, square=True, fmt='.3f', cbar_kws={'label': 'Correlation'})\n",
    "plt.title('Pearson Correlation Matrix')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "sns.heatmap(spearman_corr, annot=True, cmap='coolwarm', center=0, square=True, fmt='.3f', cbar_kws={'label': 'Correlation'})\n",
    "plt.title('Spearman Correlation Matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa340373",
   "metadata": {},
   "source": [
    "### ðŸ” Step 3: Row-wise Statistics inference (as applicable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b739e76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_columns = [col for col in columns if col != max_column_volume]\n",
    "incomings = {col : 0 for col in filtered_columns}\n",
    "outgoings = {col : 0 for col in filtered_columns}\n",
    "\n",
    "for high_col in filtered_columns:\n",
    "    for low_col in filtered_columns:\n",
    "        if high_col == low_col:\n",
    "            continue\n",
    "            \n",
    "        if (df[high_col] >= df[low_col]).all():\n",
    "            print(f\"{high_col} >= {low_col} for all rows\")\n",
    "            incomings[low_col] += 1\n",
    "            outgoings[high_col] += 1\n",
    "\n",
    "filtered_low = [col for col, value in incomings.items() if value == max(incomings.values())]\n",
    "filtered_high = [col for col, value in outgoings.items() if value == max(outgoings.values())]\n",
    "\n",
    "print(f\"\\nMost incoming column: {filtered_low} with {max(incomings.values())} incoming connections\")\n",
    "print(f\"Most outgoing column: {filtered_high} with {max(outgoings.values()) } outgoing connections\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbee5a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = df.columns.tolist()\n",
    "print(\"Columns:\", columns)\n",
    "\n",
    "filtered_columns = [col for col in columns if col != max_column_volume]\n",
    "larger = {}\n",
    "smaller = {}\n",
    "vol_pulse_large = 0\n",
    "vol_pulse_small = 0\n",
    "double_max = 0\n",
    "double_min = 0\n",
    "for col in filtered_columns:\n",
    "    larger[col] = 0\n",
    "    smaller[col] = 0\n",
    "for index,row in df.iterrows():\n",
    "    max_value = -212\n",
    "    min_value = 290\n",
    "    max_col = None\n",
    "    min_col = None\n",
    "    for col in filtered_columns:\n",
    "        if max_value < row[col]:\n",
    "            max_value = row[col]\n",
    "            max_col = col\n",
    "        if min_value > row[col]:\n",
    "            min_value = row[col]\n",
    "            min_col = col\n",
    "    larger[max_col] += 1\n",
    "    smaller[min_col] += 1\n",
    "    if max_col == \"pulse\":\n",
    "        vol_pulse_large += row[max_column_volume]\n",
    "    if min_col == \"pulse\":\n",
    "        vol_pulse_small += row[max_column_volume]\n",
    "\n",
    "for col in filtered_columns:\n",
    "    print(f\"Column {col} is largest {larger[col]} times and smallest {smaller[col]} times\")\n",
    "\n",
    "print(f\"Avg volume when pulse is high: {vol_pulse_large / larger['pulse']:.2f}\")\n",
    "print(f\"Avg volume when pulse is low: {vol_pulse_small / smaller['pulse']:.2f}\")\n",
    "\n",
    "for col in filtered_columns:\n",
    "    larger[col] = larger[col] / len(df)\n",
    "    smaller[col] = smaller[col] / len(df)\n",
    "\n",
    "large_price = 0\n",
    "max_col_high = None\n",
    "max_col_low = None\n",
    "small_price = 0\n",
    "for col in filtered_columns:\n",
    "    if large_price < larger[col]:\n",
    "        large_price = larger[col]\n",
    "        max_col_high = col\n",
    "    if small_price < smaller[col]:\n",
    "        small_price = smaller[col]\n",
    "        max_col_low = col\n",
    "\n",
    "max_col_price = None\n",
    "for col in filtered_columns:\n",
    "    if larger[col] > 0 or smaller[col] > 0:\n",
    "        max_col_price = col\n",
    "        break\n",
    "        \n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(larger.keys(), larger.values())\n",
    "plt.title('Probability of Each Column Being High')\n",
    "plt.xlabel('Columns')\n",
    "plt.ylabel('Probability')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(smaller.keys(), smaller.values())\n",
    "plt.title('Probability of Each Column Being Low')\n",
    "plt.xlabel('Columns')\n",
    "plt.ylabel('Probability')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00b150f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90791de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_open_close = [col for col in filtered_columns if col != max_col_high and col != max_col_low and col != max_col_price]\n",
    "candidate_open = candidate_open_close[0]\n",
    "candidate_close = candidate_open_close[1]\n",
    "same1 = 0\n",
    "for i in range(len(df)-1):\n",
    "    o1 = df.iloc[i][candidate_open]\n",
    "    o2 = df.iloc[i+1][candidate_open]\n",
    "    c1 = df.iloc[i][candidate_close]\n",
    "    c2 = df.iloc[i+1][candidate_close]\n",
    "    if o1  > c1 and o2 > c2 and o1 > c2:\n",
    "        same1 += 1\n",
    "    elif o1 < c1 and o2 < c2 and o1 < c2:\n",
    "        same1 += 1\n",
    "\n",
    "candidate_open = candidate_open_close[1]\n",
    "candidate_close = candidate_open_close[0]\n",
    "same2 = 0\n",
    "for i in range(len(df)-1):\n",
    "    o1 = df.iloc[i][candidate_open]\n",
    "    o2 = df.iloc[i+1][candidate_open]\n",
    "    c1 = df.iloc[i][candidate_close]\n",
    "    c2 = df.iloc[i+1][candidate_close]\n",
    "    if o1  > c1 and o2 > c2 and o1 > c2:\n",
    "        same2 += 1\n",
    "    elif o1 < c1 and o2 < c2 and o1 < c2:\n",
    "        same2 += 1\n",
    "\n",
    "print(f\"\")\n",
    "print(f\"Same1 absolute: {same1}, Same2 absolute: {same2}\")\n",
    "print(f\"Same1: {same1/(len(df)-1)}, Same2: {same2/(len(df)-1)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fec1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = len(df)\n",
    "\n",
    "candidate_open = candidate_open_close[0]\n",
    "candidate_close = candidate_open_close[1]\n",
    "works1 = 0\n",
    "for i in range(0,size,1000):\n",
    "    row1 = df.iloc[i]\n",
    "    row2 = df.iloc[i+999]\n",
    "    total_diff = row2[candidate_close] - row1[candidate_open]\n",
    "    candidate_sum = 0\n",
    "    for j in range(i,i+1000):\n",
    "        candidate_sum += df.iloc[j][candidate_close] - df.iloc[j][candidate_open]\n",
    "    if(candidate_sum > 0 and total_diff > 0):\n",
    "        works1+= 1\n",
    "    elif (candidate_sum < 0 and total_diff < 0):\n",
    "        works1+= 1\n",
    "\n",
    "candidate_open = candidate_open_close[1]\n",
    "candidate_close = candidate_open_close[0]\n",
    "works2 = 0\n",
    "for i in range(0,size,1000):\n",
    "    row1 = df.iloc[i]\n",
    "    row2 = df.iloc[i+999]\n",
    "    total_diff = row2[candidate_close] - row1[candidate_open]\n",
    "    candidate_sum = 0\n",
    "    for j in range(i,i+1000):\n",
    "        candidate_sum += df.iloc[j][candidate_close] - df.iloc[j][candidate_open]\n",
    "    if(candidate_sum > 0 and total_diff > 0):\n",
    "        works2+= 1 \n",
    "    elif (candidate_sum < 0 and total_diff < 0):\n",
    "        works2+= 1\n",
    "\n",
    "print(f\"Works1 absolute: {works1}, Works2 absolute: {works2}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde4dce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.strip()\n",
    "columns = df.columns.tolist()\n",
    "\n",
    "print(\"Columns:\", columns)\n",
    "\n",
    "df_prev = df.shift(1)\n",
    "\n",
    "results = []\n",
    "\n",
    "for open_col in ['deltaX', 'flux', 'pulse']:\n",
    "    for close_col in ['deltaX', 'flux', 'pulse']:\n",
    "        if open_col == close_col:        \n",
    "            continue\n",
    "\n",
    "        price_col = ['deltaX', 'flux', 'pulse'].copy()\n",
    "        price_col.remove(open_col)\n",
    "        price_col.remove(close_col)\n",
    "        price_col = price_col[0]\n",
    "\n",
    "        closecount = 0\n",
    "        opencount = 0\n",
    "        \n",
    "        open_distance = abs(df[price_col] - df_prev[open_col])\n",
    "        close_distance = abs(df[price_col] - df_prev[close_col])\n",
    "            \n",
    "        closer_to_open = (open_distance < close_distance).sum()\n",
    "        closer_to_close = (close_distance < open_distance).sum()\n",
    "            \n",
    "        opencount += closer_to_open\n",
    "        closecount += closer_to_close\n",
    "        \n",
    "        print(f\"\\nOpen: {open_col}, Close: {close_col}, Price: {price_col}\")\n",
    "        print(f\"Closer to Open: {opencount}\")\n",
    "        print(f\"Closer to Close: {closecount}\")\n",
    "        print(f\"Open % (lower the better): {100* opencount / (opencount + closecount):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7effbb9",
   "metadata": {},
   "source": [
    "### ðŸ“ˆ Step 4: Candlestick Visual from Mapped Fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d14a7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your logic here\n",
    "# . . . .\n",
    "# sample[['open', 'high', 'low', 'close']].plot(figsize=(12,6), title='Candlestick Field Preview')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a119cc7d",
   "metadata": {},
   "source": [
    "This confirms the structural pattern of price movement and supports the inferred mapping."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "assgn1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
